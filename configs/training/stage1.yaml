# Stage 1 Training: Global Alignment + Reconstruction
# Focus on learning geometric grounding before local alignment

# Training schedule
epochs: 100
stage1_epochs: 40  # Epochs with global + recon only

# Optimizer
optimizer:
  name: adamw
  lr: 1.0e-4
  weight_decay: 0.05
  betas: [0.9, 0.999]
  eps: 1.0e-8

# Learning rate scheduler
scheduler:
  type: cosine
  min_lr: 1.0e-6
  warmup_epochs: 5

# Loss weights
loss:
  lambda_global: 1.0
  lambda_local: 0.5  # Enabled in stage 2
  lambda_recon: 0.3
  lambda_topo: 0.1
  temperature_init: 0.07
  confidence_threshold: 0.5

# Training efficiency
gradient_accumulation: 2
effective_batch_size: 64  # batch_size * gradient_accumulation
mixed_precision: true
gradient_checkpointing: true
max_grad_norm: 1.0

# Checkpointing
save_every: 10
eval_every: 5
keep_last_n: 3
