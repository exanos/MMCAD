{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# CLIP4CAD-GFA v4.2 Training\n\n**Key Innovation: Conditional Self-Query Generation with Curriculum Learning**\n\n## Problem with v4\nThe decoder doesn't know what T_feat \"looks like\". Query distillation loss alone isn't enough.\n\n## Solution: Curriculum Learning\nDuring training, SHOW the model T_feat as a hint, then gradually remove hints.\n\n### Curriculum Schedule\n- **Epoch 1-3**: 0.1 dropout (90% samples get hints) - learn output distribution\n- **Epoch 4-7**: 0.3 dropout (70% samples get hints) - start independence\n- **Epoch 8-11**: 0.5 dropout (50% samples get hints) - balanced\n- **Epoch 12-15**: 0.7 dropout (30% samples get hints) - mostly independent\n- **Stage 2**: 1.0 dropout (0% hints) - fully independent\n\n### New Loss: Distribution Matching\n- Matches batch statistics (mean, std) of Q_self to T_feat\n- Regularizes the feature space during curriculum transition\n\n## Loss Weights\n| Stage | λ_self | λ_query | λ_dist | λ_detail |\n|-------|--------|---------|--------|----------|\n| 1 | 0.1 | **1.5** | 0.3 | 0.0 |\n| 2 | 0.3 | 1.0 | 0.2 | 0.3 |\n\n## Success Criteria\n- Self-cos BRep ≥ 0.75 (should NOT collapse!)\n- Query alignment ≥ 0.70\n- Gap (guided - self) < 10%"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 1: Imports and Setup\nimport sys\nsys.path.insert(0, '..')\n\nimport os\nimport gc\nimport math\nimport torch\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom torch.cuda.amp import GradScaler, autocast\nfrom torch.optim import AdamW\nfrom torch.optim.lr_scheduler import LambdaLR\nfrom tqdm.auto import tqdm\nimport numpy as np\nfrom pathlib import Path\nimport json\n\nfrom clip4cad.models import CLIP4CAD_GFA_v4_2, GFAv4_2Config, get_cond_dropout\nfrom clip4cad.losses import GFAv4_2Loss\nfrom clip4cad.losses.gfa_v4_2_losses import compute_self_grounding_quality, compute_query_alignment\n\n# Set device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Device: {device}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name()}\")\n    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 2: Data Paths\n\nDATA_ROOT = Path(\"d:/Defect_Det/MMCAD/data\")\nPC_FILE = Path(\"c:/Users/User/Desktop/pc_embeddings_full.h5\")\nBREP_FILE = Path(\"c:/Users/User/Desktop/brep_features.h5\")\nTEXT_FILE = Path(\"c:/Users/User/Desktop/text_embeddings.h5\")\nOUTPUT_DIR = Path(\"../outputs/gfa_v4_2\")\nOUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n\nprint(f\"Data root: {DATA_ROOT}\")\nprint(f\"PC file: {PC_FILE} (exists: {PC_FILE.exists()})\")\nprint(f\"BRep file: {BREP_FILE} (exists: {BREP_FILE.exists()})\")\nprint(f\"Text file: {TEXT_FILE} (exists: {TEXT_FILE.exists()})\")\nprint(f\"Output: {OUTPUT_DIR}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 3: Load Data using GFAMappedDataset\n\nfrom clip4cad.data.gfa_dataset import GFAMappedDataset\n\nprint(\"Loading datasets...\")\nprint(\"=\" * 60)\n\n# Train dataset - LOAD TO RAM for fast training\nprint(\"\\n[1/2] Loading TRAIN dataset to RAM...\")\ntrain_dataset = GFAMappedDataset(\n    data_root=str(DATA_ROOT),\n    split=\"train\",\n    pc_file=str(PC_FILE),\n    text_file=str(TEXT_FILE),\n    brep_file=str(BREP_FILE),\n    num_rotations=1,\n    load_to_memory=True,\n    use_live_text=False,\n)\nprint(f\"Train: {len(train_dataset):,} samples in RAM\")\n\n# Val dataset - ON DISK (saves RAM)\nprint(\"\\n[2/2] Loading VAL dataset (on disk)...\")\nval_dataset = GFAMappedDataset(\n    data_root=str(DATA_ROOT),\n    split=\"val\",\n    pc_file=str(PC_FILE),\n    text_file=str(TEXT_FILE),\n    brep_file=str(BREP_FILE),\n    num_rotations=1,\n    load_to_memory=False,\n    use_live_text=False,\n)\nprint(f\"Val: {len(val_dataset):,} samples on disk\")\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"DATASETS READY!\")\nprint(\"=\" * 60)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 4: Verify Dataset\n\nsample = train_dataset[0]\nprint(f\"Sample keys: {list(sample.keys())}\")\nprint(f\"  brep_face_features: {sample['brep_face_features'].shape}\")\nprint(f\"  brep_edge_features: {sample['brep_edge_features'].shape}\")\nprint(f\"  brep_face_mask: {sample['brep_face_mask'].shape}\")\nprint(f\"  pc_features: {sample['pc_features'].shape}\")\nprint(f\"  desc_embedding: {sample['desc_embedding'].shape}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 5: Create Model\n# NOTE: Using lighter architecture to match v2 training time\n# Original v4.2 design had 4+4 layers for BRep, but that's 6x slower than v2!\n\nconfig = GFAv4_2Config(\n    d_face=48,          # FSQ face features\n    d_edge=12,          # FSQ edge features\n    d_pc=1024,          # ShapeLLM features\n    d_text=3072,        # Phi-4-mini features\n    d_unified=256,\n    d_proj=128,\n    d_ground=128,\n    num_slots=12,\n    num_detail_queries=8,\n    num_heads=8,\n    num_parser_layers=2,\n    # LIGHTER ARCHITECTURE (was 4+4 for BRep, 2+2 for PC)\n    brep_encoder_layers=2,  # Reduced from 4\n    brep_decoder_layers=2,  # Reduced from 4\n    pc_encoder_layers=1,    # Reduced from 2\n    pc_decoder_layers=2,    # Keep at 2\n    dropout=0.1,\n)\n\nmodel = CLIP4CAD_GFA_v4_2(config).to(device)\nprint(f\"Model parameters: {model.count_parameters():,}\")\nprint(f\"Trainable parameters: {model.count_parameters(trainable_only=True):,}\")\nprint(f\"\\nArchitecture (lighter for faster training):\")\nprint(f\"  BRep: {config.brep_encoder_layers} encoder + {config.brep_decoder_layers} decoder layers\")\nprint(f\"  PC:   {config.pc_encoder_layers} encoder + {config.pc_decoder_layers} decoder layers\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 6: Training Configuration\n\nfrom clip4cad.data.gfa_dataset import gfa_collate_fn\n\n# Hyperparameters\nBATCH_SIZE = 512\nSTAGE1_EPOCHS = 15\nSTAGE2_EPOCHS = 20\nSTAGE1_LR = 3e-5\nSTAGE2_LR = 1e-5\nWARMUP_EPOCHS = 3\nMAX_GRAD_NORM = 1.0\n\n# Loss weights - v4.2 with curriculum learning\n# Stage 1: Heavy query distillation with conditioning hints\nSTAGE1_LAMBDA_SELF = 0.1\nSTAGE1_LAMBDA_QUERY = 1.5       # Heavy query distillation\nSTAGE1_LAMBDA_EMBED = 0.3\nSTAGE1_LAMBDA_DIST = 0.3        # Distribution matching\nSTAGE1_LAMBDA_DETAIL = 0.0\n\n# Stage 2: Balanced + hard negatives (no hints)\nSTAGE2_LAMBDA_SELF = 0.3\nSTAGE2_LAMBDA_QUERY = 1.0\nSTAGE2_LAMBDA_EMBED = 0.3\nSTAGE2_LAMBDA_DIST = 0.2\nSTAGE2_LAMBDA_DETAIL = 0.3\n\n# Create data loaders\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    num_workers=0,\n    pin_memory=True,\n    drop_last=True,\n    collate_fn=gfa_collate_fn,\n)\n\nval_loader = DataLoader(\n    val_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=False,\n    num_workers=0,\n    pin_memory=True,\n    collate_fn=gfa_collate_fn,\n)\n\nprint(f\"Batch size: {BATCH_SIZE}\")\nprint(f\"Train batches: {len(train_loader)}\")\nprint(f\"Val batches: {len(val_loader)}\")\nprint(f\"Total epochs: {STAGE1_EPOCHS + STAGE2_EPOCHS}\")\nprint(f\"\\nStage 1 weights: self={STAGE1_LAMBDA_SELF}, query={STAGE1_LAMBDA_QUERY}, dist={STAGE1_LAMBDA_DIST}\")\nprint(f\"Stage 2 weights: self={STAGE2_LAMBDA_SELF}, query={STAGE2_LAMBDA_QUERY}, dist={STAGE2_LAMBDA_DIST}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 7: Initialize Optimizer, Loss, Scheduler, and Hard Negative Miner\n\nfrom clip4cad.training.hard_negative_mining import HardNegativeMiner\n\noptimizer = AdamW(\n    model.parameters(),\n    lr=STAGE1_LR,\n    weight_decay=0.01,\n    betas=(0.9, 0.999),\n)\n\ncriterion = GFAv4_2Loss(\n    lambda_self=STAGE1_LAMBDA_SELF,\n    lambda_query=STAGE1_LAMBDA_QUERY,\n    lambda_embed=STAGE1_LAMBDA_EMBED,\n    lambda_dist=STAGE1_LAMBDA_DIST,\n    lambda_detail=STAGE1_LAMBDA_DETAIL,\n)\n\nscaler = GradScaler()\n\n# Learning rate scheduler with warmup\ntotal_epochs = STAGE1_EPOCHS + STAGE2_EPOCHS\nwarmup_steps = WARMUP_EPOCHS * len(train_loader)\ntotal_steps = total_epochs * len(train_loader)\n\ndef lr_lambda(step):\n    if step < warmup_steps:\n        return step / max(warmup_steps, 1)\n    progress = (step - warmup_steps) / max(total_steps - warmup_steps, 1)\n    return max(1e-6 / STAGE1_LR, 0.5 * (1 + math.cos(math.pi * progress)))\n\nscheduler = LambdaLR(optimizer, lr_lambda)\n\n# Hard negative miner (used in Stage 2)\nhard_neg_miner = HardNegativeMiner(\n    model=model,\n    train_dataloader=train_loader,\n    cache_dir=str(OUTPUT_DIR / \"hard_negatives\"),\n    k=20,\n    text_sim_threshold=0.8,\n    min_negatives=1,\n    max_negatives=10,\n    use_faiss=True,\n    device=str(device),\n)\nhard_negatives = None\nMINE_EVERY_N_EPOCHS = 5\n\nprint(\"Optimizer, loss, scheduler, and hard negative miner initialized.\")\nprint(f\"Query distillation weight: {STAGE1_LAMBDA_QUERY} (v4.2 curriculum learning)\")\nprint(f\"Distribution matching weight: {STAGE1_LAMBDA_DIST}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 8: Training State\n\n# Training state\nglobal_step = 0\nbest_val_loss = float('inf')\nbest_self_cosine = 0.0\nbest_query_align = 0.0\ncurrent_stage = 1\n\n# Training history\nhistory = {\n    'train_loss': [],\n    'val_loss': [],\n    'self_cosine_brep': [],\n    'self_cosine_pc': [],\n    'query_align_brep': [],\n    'query_align_pc': [],\n    'cond_dropout': [],\n    'dist_loss': [],\n}\n\nprint(\"Training state initialized.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 9: Training Loop with Curriculum Learning\n\nprint(\"Starting training with curriculum learning...\")\nprint(\"=\"*70)\nprint(\"Curriculum: hint rate 90% → 70% → 50% → 30% → 0%\")\nprint(\"=\"*70)\n\nfor epoch in range(1, total_epochs + 1):\n    # Stage transition\n    if epoch == STAGE1_EPOCHS + 1:\n        print(\"\\n\" + \"=\"*70)\n        print(\"TRANSITIONING TO STAGE 2 (no hints)\")\n        print(\"=\"*70)\n        current_stage = 2\n        \n        # Update loss weights\n        criterion.update_weights(\n            lambda_self=STAGE2_LAMBDA_SELF,\n            lambda_query=STAGE2_LAMBDA_QUERY,\n            lambda_embed=STAGE2_LAMBDA_EMBED,\n            lambda_dist=STAGE2_LAMBDA_DIST,\n            lambda_detail=STAGE2_LAMBDA_DETAIL,\n        )\n        print(f\"Updated loss weights: self={STAGE2_LAMBDA_SELF}, query={STAGE2_LAMBDA_QUERY}, dist={STAGE2_LAMBDA_DIST}, detail={STAGE2_LAMBDA_DETAIL}\")\n        \n        # Reduce learning rate\n        for param_group in optimizer.param_groups:\n            param_group['lr'] = STAGE2_LR\n        print(f\"Reduced LR to {STAGE2_LR}\")\n        \n        # Save Stage 1 checkpoint\n        torch.save({\n            'epoch': epoch - 1,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'best_self_cosine': best_self_cosine,\n            'best_query_align': best_query_align,\n        }, OUTPUT_DIR / 'checkpoint_stage1_final.pt')\n        print(f\"Saved Stage 1 checkpoint\")\n        \n        # Mine hard negatives at start of Stage 2\n        print(\"\\nMining hard negatives for Stage 2...\")\n        hard_negatives = hard_neg_miner.mine(epoch=epoch)\n        print(f\"Mined hard negatives for {len(hard_negatives)} samples\")\n    \n    # Re-mine hard negatives every N epochs in Stage 2\n    if current_stage == 2 and epoch > STAGE1_EPOCHS + 1:\n        if (epoch - STAGE1_EPOCHS - 1) % MINE_EVERY_N_EPOCHS == 0:\n            print(f\"\\nRe-mining hard negatives (epoch {epoch})...\")\n            hard_negatives = hard_neg_miner.mine(epoch=epoch)\n            print(f\"Re-mined hard negatives for {len(hard_negatives)} samples\")\n    \n    # ═══════════════════════════════════════════════════════════════════════\n    # CURRICULUM: Update conditioning dropout rate\n    # ═══════════════════════════════════════════════════════════════════════\n    cond_drop = get_cond_dropout(epoch, current_stage)\n    model.set_cond_dropout(cond_drop)\n    hint_rate = (1 - cond_drop) * 100\n    \n    # Train epoch\n    model.train()\n    epoch_loss = 0.0\n    epoch_self_cos_brep = []\n    epoch_self_cos_pc = []\n    epoch_query_align_brep = []\n    epoch_query_align_pc = []\n    epoch_dist_loss = []\n    \n    pbar = tqdm(train_loader, desc=f\"Epoch {epoch} (Stage {current_stage}, {hint_rate:.0f}% hints)\")\n    for batch_idx, batch in enumerate(pbar):\n        # Get hard negatives for this batch (if in Stage 2)\n        batch_hard_negs = None\n        if current_stage == 2 and hard_negatives is not None:\n            batch_size = batch['brep_face_features'].shape[0]\n            start_idx = batch_idx * BATCH_SIZE\n            batch_hard_negs = []\n            for i in range(batch_size):\n                sample_idx = start_idx + i\n                if sample_idx in hard_negatives:\n                    batch_hard_negs.append(hard_negatives[sample_idx])\n                else:\n                    batch_hard_negs.append(None)\n        \n        with autocast():\n            outputs = model(batch)\n            loss, loss_dict = criterion(outputs, hard_negatives=batch_hard_negs, stage=current_stage)\n        \n        optimizer.zero_grad()\n        scaler.scale(loss).backward()\n        scaler.unscale_(optimizer)\n        torch.nn.utils.clip_grad_norm_(model.parameters(), MAX_GRAD_NORM)\n        scaler.step(optimizer)\n        scaler.update()\n        scheduler.step()\n        \n        global_step += 1\n        epoch_loss += loss_dict['total']\n        epoch_dist_loss.append(loss_dict.get('dist', 0))\n        \n        # Compute self-grounding quality\n        if outputs.get('z_brep') is not None and outputs.get('z_brep_self') is not None:\n            cos_brep = compute_self_grounding_quality(\n                outputs['z_brep'].detach(),\n                outputs['z_brep_self'].detach()\n            )\n            epoch_self_cos_brep.append(cos_brep)\n        \n        if outputs.get('z_pc') is not None and outputs.get('z_pc_self') is not None:\n            cos_pc = compute_self_grounding_quality(\n                outputs['z_pc'].detach(),\n                outputs['z_pc_self'].detach()\n            )\n            epoch_self_cos_pc.append(cos_pc)\n        \n        # Compute query alignment\n        if outputs.get('T_feat') is not None and outputs.get('Q_brep_self') is not None:\n            q_align_brep = compute_query_alignment(\n                outputs['T_feat'].detach(),\n                outputs['Q_brep_self'].detach(),\n                outputs['confidence'].detach()\n            )\n            epoch_query_align_brep.append(q_align_brep)\n        \n        if outputs.get('T_feat') is not None and outputs.get('Q_pc_self') is not None:\n            q_align_pc = compute_query_alignment(\n                outputs['T_feat'].detach(),\n                outputs['Q_pc_self'].detach(),\n                outputs['confidence'].detach()\n            )\n            epoch_query_align_pc.append(q_align_pc)\n        \n        # Update progress bar\n        postfix = {\n            'loss': f\"{loss_dict['total']:.3f}\",\n            'guided': f\"{loss_dict['guided']:.3f}\",\n            'query': f\"{loss_dict.get('query', 0):.3f}\",\n            'dist': f\"{loss_dict.get('dist', 0):.3f}\",\n            'cos': f\"{epoch_self_cos_brep[-1]:.3f}\" if epoch_self_cos_brep else \"N/A\",\n            'q_align': f\"{epoch_query_align_brep[-1]:.3f}\" if epoch_query_align_brep else \"N/A\",\n        }\n        if current_stage == 2:\n            postfix['detail'] = f\"{loss_dict.get('detail', 0):.3f}\"\n        pbar.set_postfix(postfix)\n    \n    # Epoch summary\n    avg_loss = epoch_loss / len(train_loader)\n    avg_cos_brep = sum(epoch_self_cos_brep) / len(epoch_self_cos_brep) if epoch_self_cos_brep else 0\n    avg_cos_pc = sum(epoch_self_cos_pc) / len(epoch_self_cos_pc) if epoch_self_cos_pc else 0\n    avg_q_align_brep = sum(epoch_query_align_brep) / len(epoch_query_align_brep) if epoch_query_align_brep else 0\n    avg_q_align_pc = sum(epoch_query_align_pc) / len(epoch_query_align_pc) if epoch_query_align_pc else 0\n    avg_dist_loss = sum(epoch_dist_loss) / len(epoch_dist_loss) if epoch_dist_loss else 0\n    \n    history['train_loss'].append(avg_loss)\n    history['self_cosine_brep'].append(avg_cos_brep)\n    history['self_cosine_pc'].append(avg_cos_pc)\n    history['query_align_brep'].append(avg_q_align_brep)\n    history['query_align_pc'].append(avg_q_align_pc)\n    history['cond_dropout'].append(cond_drop)\n    history['dist_loss'].append(avg_dist_loss)\n    \n    if avg_cos_brep > best_self_cosine:\n        best_self_cosine = avg_cos_brep\n    if avg_q_align_brep > best_query_align:\n        best_query_align = avg_q_align_brep\n    \n    print(f\"\\nEpoch {epoch}: Loss={avg_loss:.4f}, Self-cos BRep={avg_cos_brep:.4f}, PC={avg_cos_pc:.4f}\")\n    print(f\"  Query-align BRep={avg_q_align_brep:.4f}, PC={avg_q_align_pc:.4f}\")\n    print(f\"  cond_dropout={cond_drop:.1f} ({hint_rate:.0f}% hints), dist_loss={avg_dist_loss:.4f}\")\n    print(f\"  Best: self-cos={best_self_cosine:.4f}, query-align={best_query_align:.4f}\")\n    \n    # Validation every 5 epochs\n    if epoch % 5 == 0:\n        model.eval()\n        val_loss = 0.0\n        val_cos_brep = []\n        \n        with torch.no_grad():\n            for batch in tqdm(val_loader, desc=\"Validation\"):\n                with autocast():\n                    outputs = model(batch)\n                    loss, loss_dict = criterion(outputs, stage=current_stage)\n                val_loss += loss_dict['total']\n                \n                if outputs.get('z_brep') is not None and outputs.get('z_brep_self') is not None:\n                    cos_brep = compute_self_grounding_quality(\n                        outputs['z_brep'],\n                        outputs['z_brep_self']\n                    )\n                    val_cos_brep.append(cos_brep)\n        \n        avg_val_loss = val_loss / len(val_loader)\n        avg_val_cos = sum(val_cos_brep) / len(val_cos_brep) if val_cos_brep else 0\n        \n        history['val_loss'].append(avg_val_loss)\n        print(f\"Validation: Loss={avg_val_loss:.4f}, Self-cos={avg_val_cos:.4f}\")\n        \n        # Save best model\n        if avg_val_loss < best_val_loss:\n            best_val_loss = avg_val_loss\n            torch.save({\n                'epoch': epoch,\n                'model_state_dict': model.state_dict(),\n                'best_val_loss': best_val_loss,\n                'best_self_cosine': best_self_cosine,\n                'best_query_align': best_query_align,\n            }, OUTPUT_DIR / 'checkpoint_best.pt')\n            print(\"Saved best model!\")\n    \n    # Save checkpoint every 5 epochs\n    if epoch % 5 == 0:\n        torch.save({\n            'epoch': epoch,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'scheduler_state_dict': scheduler.state_dict(),\n            'best_self_cosine': best_self_cosine,\n            'best_query_align': best_query_align,\n        }, OUTPUT_DIR / f'checkpoint_epoch{epoch}.pt')\n    \n    # Clear cache\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n        gc.collect()\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"Training Complete!\")\nprint(f\"Best self-grounding cosine: {best_self_cosine:.4f}\")\nprint(f\"Best query alignment: {best_query_align:.4f}\")\nprint(f\"Best validation loss: {best_val_loss:.4f}\")\nprint(\"=\"*70)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 10: Save Final Model\n\ntorch.save({\n    'model_state_dict': model.state_dict(),\n    'config': config.__dict__,\n    'best_self_cosine': best_self_cosine,\n    'best_query_align': best_query_align,\n    'history': history,\n}, OUTPUT_DIR / 'clip4cad_gfa_v4_2_final.pt')\n\nprint(f\"Final model saved to {OUTPUT_DIR / 'clip4cad_gfa_v4_2_final.pt'}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 11: Plot Training History\n\nimport matplotlib.pyplot as plt\n\nfig, axes = plt.subplots(2, 3, figsize=(15, 10))\n\n# Loss plot\nax = axes[0, 0]\nax.plot(history['train_loss'], label='Train Loss')\nif history['val_loss']:\n    val_epochs = list(range(5, len(history['train_loss']) + 1, 5))[:len(history['val_loss'])]\n    ax.plot(val_epochs, history['val_loss'], 'o-', label='Val Loss')\nax.axvline(x=STAGE1_EPOCHS, color='r', linestyle='--', label='Stage 2')\nax.set_xlabel('Epoch')\nax.set_ylabel('Loss')\nax.set_title('Training Loss')\nax.legend()\nax.grid(True)\n\n# Self-grounding quality\nax = axes[0, 1]\nax.plot(history['self_cosine_brep'], label='BRep')\nax.plot(history['self_cosine_pc'], label='PC')\nax.axvline(x=STAGE1_EPOCHS, color='r', linestyle='--', label='Stage 2')\nax.axhline(y=0.7, color='g', linestyle=':', label='Target')\nax.set_xlabel('Epoch')\nax.set_ylabel('Cosine Similarity')\nax.set_title('Self-Grounding Quality')\nax.legend()\nax.grid(True)\n\n# Query alignment\nax = axes[0, 2]\nax.plot(history['query_align_brep'], label='BRep')\nax.plot(history['query_align_pc'], label='PC')\nax.axvline(x=STAGE1_EPOCHS, color='r', linestyle='--', label='Stage 2')\nax.axhline(y=0.7, color='g', linestyle=':', label='Target')\nax.set_xlabel('Epoch')\nax.set_ylabel('Cosine Similarity')\nax.set_title('Query Alignment (T_feat vs Q_self)')\nax.legend()\nax.grid(True)\n\n# Curriculum (cond_dropout)\nax = axes[1, 0]\nax.plot(history['cond_dropout'], 'b-', linewidth=2)\nax.axvline(x=STAGE1_EPOCHS, color='r', linestyle='--', label='Stage 2')\nax.set_xlabel('Epoch')\nax.set_ylabel('Conditioning Dropout Rate')\nax.set_title('Curriculum Schedule (0=all hints, 1=no hints)')\nax.set_ylim(-0.05, 1.05)\nax.grid(True)\n\n# Distribution loss\nax = axes[1, 1]\nax.plot(history['dist_loss'], label='Distribution Loss')\nax.axvline(x=STAGE1_EPOCHS, color='r', linestyle='--', label='Stage 2')\nax.set_xlabel('Epoch')\nax.set_ylabel('Loss')\nax.set_title('Distribution Matching Loss')\nax.legend()\nax.grid(True)\n\n# BRep vs PC comparison\nax = axes[1, 2]\nax.plot(history['self_cosine_brep'], label='Self-cos BRep')\nax.plot(history['query_align_brep'], label='Query-align BRep', linestyle='--')\nax.axvline(x=STAGE1_EPOCHS, color='r', linestyle='--', label='Stage 2')\nax.set_xlabel('Epoch')\nax.set_ylabel('Cosine Similarity')\nax.set_title('BRep: Self-cos vs Query-align')\nax.legend()\nax.grid(True)\n\nplt.tight_layout()\nplt.savefig(OUTPUT_DIR / 'training_history.png', dpi=150)\nplt.show()\n\nprint(f\"Plot saved to {OUTPUT_DIR / 'training_history.png'}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 12: Summary\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"TRAINING SUMMARY - GFA v4.2 (Curriculum Learning)\")\nprint(\"=\"*70)\nprint(f\"\\nFinal metrics:\")\nprint(f\"  Self-cos BRep: {history['self_cosine_brep'][-1]:.4f}\")\nprint(f\"  Self-cos PC:   {history['self_cosine_pc'][-1]:.4f}\")\nprint(f\"  Query-align BRep: {history['query_align_brep'][-1]:.4f}\")\nprint(f\"  Query-align PC:   {history['query_align_pc'][-1]:.4f}\")\nprint(f\"\\nBest metrics:\")\nprint(f\"  Best self-cosine: {best_self_cosine:.4f}\")\nprint(f\"  Best query-align: {best_query_align:.4f}\")\nprint(f\"  Best val loss: {best_val_loss:.4f}\")\nprint(f\"\\nModel saved to: {OUTPUT_DIR / 'clip4cad_gfa_v4_2_final.pt'}\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}